{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pre2_savefile.ipynb","provenance":[],"authorship_tag":"ABX9TyM1TnV4yR8Ftht+wJYA/l2y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnyQiWnkwIgk","executionInfo":{"status":"ok","timestamp":1619306813261,"user_tz":240,"elapsed":4188,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"44aafbee-0a62-4fd0-ef7b-8796d394fc9b"},"source":["!pip install gensim"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-qAEz8vwlxn","executionInfo":{"status":"ok","timestamp":1619306832284,"user_tz":240,"elapsed":19015,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"f07d0882-0556-4549-89c4-5f89dca970ee"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6s87uWrvwv1_","executionInfo":{"status":"ok","timestamp":1619306832535,"user_tz":240,"elapsed":19259,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"712de933-1c52-443b-c4e2-020d16ce00d1"},"source":["!cd gdrive/My' 'Drive/Colab' 'Notebooks\n","!ls gdrive/My' 'Drive/Colab' 'Notebooks\n","import os\n","os.chdir(\"gdrive/My Drive/Colab Notebooks\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":[" bertmodel\t\t        modelvc_colab.model.trainables.syn1neg.npy\n"," bert_trained.png\t        modelvc_colab.model.wv.vectors.npy\n"," bot_model3.py\t\t        modelvc.model\n"," bot_model_fin2.py\t        modelvc.model.syn1neg.npy\n"," bot_model_final.py\t        modelvc.model.wv.vectors.npy\n"," bot_model_fin.py\t        movie_conversations.txt\n"," bot_models.py\t\t        movie_lines.txt\n"," bot_train_savefile.py\t        pre2_run.ipynb\n"," conv.txt\t\t        pre2_savefile.ipynb\n","'Copy of pre2_savefile.ipynb'   pre.ipynb\n","'Copy of pre.ipynb'\t        __pycache__\n"," data_2.json\t\t        questions-word2s.txt\n"," datapre.py\t\t        questions-words.txt\n"," embeddings_colab.kv\t        td.txt\n"," embeddings.kv\t\t        test.txt\n"," fc_net_git.py\t\t        Untitled\n"," fc_net.py\t\t        Untitled1.ipynb\n"," layers\t\t\t        Untitled2.ipynb\n"," model\t\t\t        Untitled3.ipynb\n"," modelvc_colab.model\t        w2v.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uN1Q_5zxwVzs","executionInfo":{"status":"ok","timestamp":1619306837257,"user_tz":240,"elapsed":23979,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["from datapre import word2vec\n","import numpy as np\n","import json\n","\n","settings = {\n","    'window_size': 2,\n","    'n': 200,\n","    'epochs': 100,\n","    'learning_rate':0.1,\n","    'randepochs':0\n","}\n","dataname = \"data_2.json\"\n","max_seq_len = 10\n","limit = 10000000\n","def plot():\n","    from numpy import linalg as LA\n","\n","    with open(dataname) as json_file:\n","        data = json.load(json_file)\n","\n","    words = list(data.keys())\n","    v_count = len(words)\n","    n = settings['n']\n","    input = np.zeros((v_count, n))\n","\n","    dim = n\n","    input = np.zeros((v_count, n))\n","    for i in range(v_count):\n","        word = words[i]\n","        input[i, :] = data[word]\n","    input = input.T\n","    Cov = 1 / dim * input.dot(input.T)\n","    w, v2 = LA.eig(Cov)\n","    wid = np.argsort(w)\n","    wid_1 = wid[dim - 1]\n","    wid_2 = wid[dim - 2]\n","    v = np.zeros((dim, 2))\n","    v[:, 0] = v2[:, wid_1]\n","    v[:, 1] = v2[:, wid_2]\n","    output = input\n","    output = v.T.dot(input)\n","    import matplotlib.pyplot as plt\n","    fig, ax = plt.subplots()\n","    ax.scatter(output[0,:],output[1,:])\n","    #maxx = np.max(output[0,:])\n","    #maxy = np.max(output[1, :])\n","    #minx = np.min(output[0, :])\n","    #miny = np.min(output[1, :])\n","    for i in range(v_count):\n","      ax.annotate(words[i],(output[0,i],output[1,i]))\n","    ax.axis('auto')\n","    ax.set_autoscale_on(True)\n","    #ax.plot([minx,maxx],[miny,maxy])\n","    plt.show()\n","\n","def movieinput():\n","    import pandas as pd\n","    import numpy as np\n","    import tensorflow as tf\n","    import re\n","    import time\n","    lines = open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n","    conv_lines = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n","    id2line = {}\n","    for line in lines:\n","        _line = line.split(' +++$+++ ')\n","        if len(_line) == 5:\n","            id2line[_line[0]] = _line[4]\n","    convs = []\n","    for line in conv_lines[:-1]:\n","        _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n","        convs.append(_line.split(','))\n","    questions = []\n","    answers = []\n","\n","    for conv in convs:\n","        for i in range(len(conv) - 1):\n","            questions.append(id2line[conv[i]])\n","            answers.append(id2line[conv[i + 1]])\n","    corpust = questions + answers\n","    corpus = [re.sub(r'[^A-Za-z0-9 -]+', '', word.lower()) + ' <EOS>' for word in corpust]\n","    return corpus"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"jAo-k3KtyxCw","executionInfo":{"status":"ok","timestamp":1619306842010,"user_tz":240,"elapsed":4749,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["corpus = movieinput()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"BSlqUECIy7ly","executionInfo":{"status":"ok","timestamp":1619306901973,"user_tz":240,"elapsed":60336,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["corpus2 = [word.split() for word in corpus]\n","from gensim.models import Word2Vec, KeyedVectors\n","model = Word2Vec(corpus2, min_count = 1, size=200, window=5,  workers=4)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"QhxKuhsizI09","executionInfo":{"status":"ok","timestamp":1619306908227,"user_tz":240,"elapsed":63549,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["with open(\"/content/gdrive/MyDrive/Colab Notebooks/embeddings_colab.kv\", \"wb\") as handle:\n","    model.wv.save(handle)\n","model.save(\"/content/gdrive/MyDrive/Colab Notebooks/modelvc_colab.model\")"],"execution_count":7,"outputs":[]}]}