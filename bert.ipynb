{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert.ipynb","provenance":[],"authorship_tag":"ABX9TyOWjyIvBUT5MTwUR1NIu+Ia"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zelviO5JOGAh","executionInfo":{"status":"ok","timestamp":1619407813343,"user_tz":240,"elapsed":19711,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"bd253a32-e634-4c74-be71-89ba3aea792e"},"source":["!pip install keras_bert\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import re\n","import time\n","import keras\n","from keras_bert import get_base_dict, get_model, compile_model, gen_batch_inputs"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting keras_bert\n","  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_bert) (1.19.5)\n","Requirement already satisfied: Keras>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from keras_bert) (2.4.3)\n","Collecting keras-transformer>=0.38.0\n","  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.4.3->keras_bert) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.4.3->keras_bert) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.4.3->keras_bert) (2.10.0)\n","Collecting keras-pos-embd>=0.11.0\n","  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n","Collecting keras-multi-head>=0.27.0\n","  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n","Collecting keras-layer-normalization>=0.14.0\n","  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n","Collecting keras-position-wise-feed-forward>=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n","Collecting keras-embed-sim>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras>=2.4.3->keras_bert) (1.15.0)\n","Collecting keras-self-attention==0.46.0\n","  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n","Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-bert: filename=keras_bert-0.86.0-cp37-none-any.whl size=34144 sha256=1bd82b45f3b75223837335cd2cb44d052fe374e34c4f8f04d0bc00341a12dba7\n","  Stored in directory: /root/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp37-none-any.whl size=12942 sha256=a3606dfe091650adff513cde15a25e2284846d17ebbe36dcef076563cb5b93f9\n","  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp37-none-any.whl size=7554 sha256=b29ed87ecc3572f365c211ccc47036726f30321860d5172243194acc940447aa\n","  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp37-none-any.whl size=15611 sha256=76faacf97a713548136297e9fd074d7fe3e902626e580c0231bf5913b776dcd1\n","  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp37-none-any.whl size=5269 sha256=e2a2b7fc2c43ec15d4cf49ce9aa67de97e6d7556c97942088eda14ecc18ba426\n","  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp37-none-any.whl size=5623 sha256=00e7a8fe394fffda454c99d807700cbff2ad479c9fd746b8759cbb96ee4c3a63\n","  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp37-none-any.whl size=4558 sha256=e897f1b5b1d4701787191020983b790bf5a78d946eb04629c5be1d95452e9f29\n","  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp37-none-any.whl size=17278 sha256=15425e647852cfbba7ca87042823186c5d58da46c3800253d6b5616f2bea085e\n","  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n","Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n","Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n","Successfully installed keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JD8jU9c_Oecn","executionInfo":{"status":"ok","timestamp":1619407837290,"user_tz":240,"elapsed":17903,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"5e734ed2-a252-470a-d4f5-63fe83bda0d0"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","!cd gdrive/My' 'Drive/Colab' 'Notebooks\n","!ls gdrive/My' 'Drive/Colab' 'Notebooks\n","import os\n","os.chdir(\"gdrive/My Drive/Colab Notebooks\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"," bert.ipynb\t\t        modelvc_colab.model.trainables.syn1neg.npy\n"," bertmodel\t\t        modelvc_colab.model.wv.vectors.npy\n"," bert_trained.png\t        modelvc.model\n"," bot_model3.py\t\t        modelvc.model.syn1neg.npy\n"," bot_model_fin2.py\t        modelvc.model.wv.vectors.npy\n"," bot_model_final.py\t        movie_conversations.txt\n"," bot_model_fin.py\t        movie_lines.txt\n"," bot_models.py\t\t        pre2_run.ipynb\n"," bot_train_savefile.py\t        pre2_savefile.ipynb\n"," conv.txt\t\t        pre.ipynb\n","'Copy of pre2_savefile.ipynb'   __pycache__\n","'Copy of pre.ipynb'\t        questions-word2s.txt\n"," data_2.json\t\t        questions-words.txt\n"," datapre.py\t\t        td.txt\n"," embeddings_colab.kv\t        test.txt\n"," embeddings.kv\t\t        uncased_L-2_H-128_A-2\n"," fc_net_git.py\t\t        Untitled\n"," fc_net.py\t\t        Untitled0.ipynb\n"," layers\t\t\t        Untitled1.ipynb\n"," model\t\t\t        Untitled2.ipynb\n"," model_plot.png\t\t        Untitled3.ipynb\n"," modelvc_colab.model\t        w2v.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"26D4MlLsPX2h","executionInfo":{"status":"ok","timestamp":1619408264244,"user_tz":240,"elapsed":173,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["def movieinput():\n","    import pandas as pd\n","    import numpy as np\n","    import tensorflow as tf\n","    import re\n","    import time\n","    lines = open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n","    conv_lines = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n","    id2line = {}\n","    for line in lines:\n","        _line = line.split(' +++$+++ ')\n","        if len(_line) == 5:\n","            id2line[_line[0]] = _line[4]\n","    convs = []\n","    for line in conv_lines[:-1]:\n","        _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n","        convs.append(_line.split(','))\n","    questions = []\n","    answers = []\n","    corpus = []\n","    for conv in convs:\n","        for i in range(len(conv) - 1):\n","            cot = [id2line[conv[i]], id2line[conv[i + 1]]]\n","            corpus.append(cot)\n","    return corpus"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"vCzU9zPePkNN","executionInfo":{"status":"ok","timestamp":1619408266854,"user_tz":240,"elapsed":1526,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["corpus = movieinput()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pA8TL0jpPnDu","executionInfo":{"status":"ok","timestamp":1619408268368,"user_tz":240,"elapsed":200,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"8628c642-00ca-4f9e-ca11-282cf4e190ee"},"source":["corpus[1:10]"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[\"Well, I thought we'd start with pronunciation, if that's okay with you.\",\n","  'Not the hacking and gagging and spitting part.  Please.'],\n"," ['Not the hacking and gagging and spitting part.  Please.',\n","  \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\"],\n"," [\"You're asking me out.  That's so cute. What's your name again?\",\n","  'Forget it.'],\n"," [\"No, no, it's my fault -- we didn't have a proper introduction ---\",\n","  'Cameron.'],\n"," ['Cameron.',\n","  \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\"],\n"," [\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\",\n","  'Seems like she could get a date easy enough...'],\n"," ['Why?',\n","  'Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.'],\n"," ['Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.',\n","  \"That's a shame.\"],\n"," ['Gosh, if only we could find Kat a boyfriend...',\n","  'Let me see what I can do.']]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"Qwo-tzjqQUwW","executionInfo":{"status":"ok","timestamp":1619409198211,"user_tz":240,"elapsed":2245,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["model_path = 'uncased_L-2_H-128_A-2'\n","from keras_bert import extract_embeddings\n","embeddings = extract_embeddings(model_path, corpus[1])"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-gw_G5uQoVw","executionInfo":{"status":"ok","timestamp":1619409199338,"user_tz":240,"elapsed":372,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"fba05b09-948e-4eed-9d58-10e7f89e8e95"},"source":["len(embeddings)"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KaLy1RLQ8m8","executionInfo":{"status":"ok","timestamp":1619409203283,"user_tz":240,"elapsed":365,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"48c51bc2-e034-4bb6-fbf0-f742d6be9967"},"source":["len(embeddings[0])"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zW-FpJVpQ_cb","executionInfo":{"status":"ok","timestamp":1619409207366,"user_tz":240,"elapsed":198,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"a78d05ec-a2a2-4b3c-ac4f-a0a47a3feb04"},"source":["len(embeddings[0][0])"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w__Vop3QTwL-","executionInfo":{"status":"ok","timestamp":1619409214604,"user_tz":240,"elapsed":181,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"1edc3e3c-566c-4db1-89ea-5a15b63d1656"},"source":["embeddings"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[-1.5220592 ,  0.50088394, -3.4219606 , ...,  0.45740902,\n","         -0.45696044,  0.97163993],\n","        [-1.6494675 ,  0.9875897 ,  0.03026113, ..., -1.3667037 ,\n","         -0.8411627 ,  0.67170614],\n","        [-1.804443  ,  0.34176323,  0.13734329, ..., -1.4380163 ,\n","         -1.0494798 ,  0.85824823],\n","        ...,\n","        [-0.82620764,  0.6032084 , -0.03958166, ..., -0.8831636 ,\n","         -0.55166745, -0.12525228],\n","        [-0.6985612 ,  0.483358  , -0.04208551, ..., -0.68918407,\n","         -1.1334566 , -0.27376273],\n","        [-1.965588  ,  0.33203375,  0.18568626, ..., -0.84344494,\n","         -0.65154445,  1.2338033 ]], dtype=float32),\n"," array([[-1.8759732 ,  0.13834034, -2.9566934 , ...,  0.05538473,\n","         -0.8409858 ,  0.8340823 ],\n","        [-1.3315489 ,  1.3347914 ,  0.02588546, ..., -1.0139276 ,\n","         -0.9998584 ,  1.6313146 ],\n","        [-2.2180653 ,  0.8426324 ,  0.10486621, ..., -1.3958938 ,\n","         -1.4867004 ,  0.7733764 ],\n","        ...,\n","        [-1.4714628 ,  1.2466362 ,  0.04664433, ..., -1.8756769 ,\n","         -1.0077902 ,  0.69561607],\n","        [-0.67752236,  0.82109714,  0.55294836, ..., -0.9566386 ,\n","         -1.6222175 , -0.3797667 ],\n","        [-2.2448409 ,  0.94326097,  0.65803814, ..., -1.1167334 ,\n","         -0.88809216,  1.1412516 ]], dtype=float32)]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"hoCR8_KARL39","executionInfo":{"status":"ok","timestamp":1619452592375,"user_tz":240,"elapsed":828,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["class MySeq2Seq(object):\n","\n","    def __init__(self, max_seq_len = 10, word_vec_dim = 128, input_file='./segment_result_lined.3000000.pair.less'):\n","        self.max_seq_len = max_seq_len\n","        self.word_vec_dim = word_vec_dim\n","        self.input_file = input_file\n","        self.setup = False\n","        self.vocabsize = 0\n","    \n","    def generate_trainig_data(self):\n","\n","        import re\n","        if not self.setup:\n","          lines = open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n","          conv_lines = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n","          id2line = {}\n","          for line in lines:\n","            _line = line.split(' +++$+++ ')\n","            if len(_line) == 5:\n","                id2line[_line[0]] = _line[4]\n","          convs = []\n","          for line in conv_lines[:-1]:\n","            _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n","            convs.append(_line.split(','))\n","          questions = []\n","          answers = []\n","\n","\n","          for conv in convs:\n","            for i in range(len(conv) - 1):\n","                questions.append(id2line[conv[i]])\n","                answers.append(id2line[conv[i + 1]])\n","          question = [re.sub(r'[^A-Za-z0-9 -]+', '', word.lower())  for word in questions]\n","          answer = [re.sub(r'[^A-Za-z0-9 -]+', '', word.lower())  for word in answers]\n","          #self.setup = True\n","        x_data = []\n","        y_data = []\n","        t_data = []\n","        self.vocabsize = len(question)\n","        for i in range(min(len(question),limit)):\n","        #for i in range(100):\n","            question_seq = question[i]\n","            answer_seq = answer[i]\n","            [question_seq, answer_seq] = extract_embeddings(model_path, [question_seq, answer_seq])\n","            question_seq = question_seq.tolist()\n","            answer_seq = answer_seq.tolist()\n","            if len(question_seq) < self.max_seq_len and len(answer_seq) < self.max_seq_len and i<limit:\n","                print(i);\n","                sequence_x = list(question_seq) + [dmin*np.ones(self.word_vec_dim)] * (self.max_seq_len-len(question_seq))\n","                sequence_y2 = [dmax*np.ones(self.word_vec_dim)] + answer_seq\n","                sequence_t = answer_seq + [-dmax*np.ones(self.word_vec_dim)]\n","                sequence_y2 = sequence_y2 + [dmin * np.ones(self.word_vec_dim)] * (self.max_seq_len - len(answer_seq) - 1)\n","                sequence_t = sequence_t + [dmin * np.ones(self.word_vec_dim)] * (\n","                            self.max_seq_len - len(answer_seq) - 1)\n","                x_data.append(sequence_x)\n","                y_data.append(sequence_y2)\n","                t_data.append(sequence_t)\n","               # ttt11 = question[i]\n","               # ttt2 = answer[i]\n","               # ttt2\n","                #print \"right answer\"\n","                #for w in answer_seq:\n","                #    (match_word, max_cos) = vector2word(w)\n","                #    if len(match_word)>0:\n","                #        print match_word, vector_sqrtlen(w)\n","\n","        return np.array(x_data), np.array(y_data),np.array(t_data)\n","\n","    def generate_test(self,str):\n","        from gensim.models import Word2Vec, KeyedVectors\n","        data = KeyedVectors.load(wordvecname)\n","        ##############\n","        datatt = len(data['you'])\n","        self.word_vec_dim = datatt\n","        import re\n","        str =re.sub(r'[^A-Za-z0-9 -]+', '', str.lower())\n","        question_seq = extract_embeddings(model_path, [str])\n","        question_seq = question_seq\n","        X = []\n","        y = []\n","        tmp1 = question_seq\n","        [tmp1] = tmp1\n","        tmp1 = tmp1.tolist()\n","        tmp1 = [np.array(tmpp) for tmpp in tmp1]\n","        if len(tmp1) < self.max_seq_len:\n","                #sequence_x =  list(tmp1) + [np.zeros(word_vec_dim)] * (self.max_seq_len - len(tmp1))\n","                sequence_x = list(tmp1) + [0* np.ones(word_vec_dim)] * (\n","                            self.max_seq_len - len(question_seq))\n","                # sequence_xy = list(tmp1) + [np.zeros(word_vec_dim)] * (self.max_seq_len - len(tmp1))\n","                sequence_y = [np.zeros(word_vec_dim)] * self.max_seq_len\n","                X.append(sequence_x)\n","        return np.array(X)\n","\n","    def define_models(self,n_input, n_output, n_units):\n","        import keras\n","        from tensorflow.keras import layers\n","        # define training encoder\n","\n","        encoder_inputs = layers.Input(shape=(None, n_input))\n","\n","     #   encoder_batch = BatchNormalization()\n","     #   encoder_inputt =  encoder_batch(encoder_inputs)\n","\n","        encoder =   layers.LSTM(n_units, return_state=True)\n","        encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","        encoder_states = [state_h, state_c]\n","       # encoder_outputs, state_h, state_c = encoder(encoder_inputs,initial_state=encoder_states)\n","       # encoder_states = [state_h, state_c]\n","        # define training decoder\n","\n","        decoder_inputs = layers.Input(shape=(None, n_output))\n","        decoder_lstm = layers.LSTM(n_units, return_sequences=True, return_state=True)\n","\n","\n","        decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","      #  decoder_dense = layers.Dense(n_output)\n","        decoder_dense  = keras.Sequential(\n","    [\n","        layers.Dense(n_output, activation=\"tanh\", name=\"layer1\"),\n","        layers.Dense(n_output, activation=\"tanh\", name=\"layer2\"),\n","        layers.Dense(n_output, activation=\"tanh\", name=\"layer3\"),\n","      #  layers.Dense(n_output, activation=\"tanh\", name=\"layer4\"),\n","     #   layers.Dense(n_output, activation=\"tanh\", name=\"layer5\"),\n","    #    layers.Dense(n_output, activation=\"tanh\", name=\"layer6\"),\n","     #   layers.Dense(n_output, activation=\"tanh\", name=\"layer7\"),\n","     #   layers.Dense(n_output, activation=\"tanh\", name=\"layer8\"),\n","    #    layers.Dense(n_output, activation=\"tanh\", name=\"layer9\"),\n","\n","        layers.Dense(n_output, name=\"layerfin\"),\n","    ]\n","    )\n","\n","        decoder_outputs = decoder_dense(decoder_outputs)\n","        model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","        # define inference encoder\n","        encoder_model = keras.Model(encoder_inputs, encoder_states)\n","        # define inference decoder\n","\n","\n","        decoder_state_input_h = layers.Input(shape=(n_units,))\n","        decoder_state_input_c = layers.Input(shape=(n_units,))\n","        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","        decoder_states = [state_h, state_c]\n","        decoder_outputs = decoder_dense(decoder_outputs)\n","        decoder_model = keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n","        # return all models\n","        return model, encoder_model, decoder_model\n","\n","\n","\n","\n","    def train(self):\n","        import matplotlib.pyplot as plt\n","        trainXY, trainY, traint = self.generate_trainig_data()\n","        model, infenc, infdec = self.define_models(word_vec_dim,word_vec_dim,word_vec_dim)\n","       # model = self.model(feed_previous=False)\n","        optimizer = keras.optimizers.Adam(lr=0.1)\n","        model.compile(optimizer=optimizer, loss='cosine_similarity', metrics=['accuracy'])\n","        history = model.fit([trainXY, trainY],traint,epochs=ep)\n","        model.save('./model/bot')\n","        infenc.save('./model/encoder')\n","        infdec.save('./model/decoder')\n","        print('saved')\n","        plt.plot(history.history['acc'])\n","        plt.title('0.1 lr')\n","        plt.ion()\n","        plt.pause(0.1)\n","        plt.show()\n","      #   model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n","        # list all data in history\n","        return model\n","\n","    def train2(self):\n","        import matplotlib.pyplot as plt\n","        trainXY, trainY, traint = self.generate_trainig_data()\n","        model, infenc, infdec = self.define_models(word_vec_dim, word_vec_dim, word_vec_dim)\n","        # model = self.model(feed_previous=False)\n","        optimizer = keras.optimizers.Adam(lr=0.0005)\n","        model.compile(optimizer=optimizer, loss='cosine_similarity', metrics=[soft_acc])\n","        history = model.fit([trainXY, trainY], traint, epochs=ep,shuffle=True )\n","        model.save('./model/botfinb')\n","        infenc.save('./model/encoderfinb')\n","        infdec.save('./model/decoderfinb')\n","        print('saved')\n","        plt.plot(history.history['loss'])\n","        plt.title('model14')\n","        plt.show()\n","        #   model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n","        # list all data in history\n","        return model\n","\n","    def load(self):\n","        dependencies = {\n","            'soft_acc': soft_acc\n","        }\n","        from keras.models import load_model\n","        #model = self.model(feed_previous=True)\n","        self.model= load_model('./model/botfinb',custom_objects=dependencies )\n","        self.infenc= load_model('./model/encoderfinb',custom_objects=dependencies )\n","        self.infdec= load_model('./model/decoderfinb',custom_objects=dependencies )\n","        print(self.model.summary())\n","        from keras.utils.vis_utils import plot_model\n","        plot_model(self.model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n","\n","\n","    def mypredict(self, source, n_steps, cardinality):\n","        # encode\n","        infenc = self.infenc\n","        infdec = self.infdec\n","        state = infenc.predict(source)\n","        # start of sequence input\n","        target_seq = np.array([1.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n","        # collect predictions\n","        output = list()\n","        for t in range(n_steps):\n","            # predict next char\n","            yhat, h, c = infdec.predict([target_seq] + state)\n","            # store prediction\n","            output.append(yhat[0, 0, :])\n","            # update state\n","            state = [h, c]\n","            # update target sequence\n","            target_seq = yhat\n","            #target_seq = np.array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n","        return np.array(output)"],"execution_count":203,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3h5O-AfV6RA","executionInfo":{"status":"ok","timestamp":1619414836998,"user_tz":240,"elapsed":3016,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["max_w = 10\n","float_size = 4\n","wordvecname = \"embeddings_colab.kv\"\n","from gensim.models import Word2Vec, KeyedVectors\n","word_vector_dict = KeyedVectors.load(wordvecname)\n","word_vec_dim = 128\n","max_seq_len = 10\n","word_set = {}\n","limit = 10000\n","ep = 500\n","wordvc =  Word2Vec.load(\"modelvc_colab.model\")\n","data = KeyedVectors.load(wordvecname)\n","dmax = 1#np.max(data.vectors) # 1 : value for <pad> and <eos>\n","dmin = 0#np.min(data.vectors) # 0 : value for <go>\n"],"execution_count":109,"outputs":[]},{"cell_type":"code","metadata":{"id":"NdLmBRMRbqYP","executionInfo":{"status":"ok","timestamp":1619411306229,"user_tz":240,"elapsed":203,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["def init_seq(input_file):\n","    \"\"\"读取切好词的文本文件，加载全部词序列\n","    \"\"\"\n","\n","\n","    ##############\n","    datatt = len(word_vector_dict['you'])\n","    word_vec_dim = datatt\n","\n","    file_object = open(input_file, 'r')\n","    vocab_dict = {}\n","    while True:\n","        question_seq = []\n","        answer_seq = []\n","        line = file_object.readline()\n","        if line:\n","            line_pair = line.split('|')\n","            line_question = line_pair[0]\n","            line_answer = line_pair[1]\n","            for word in line_question.decode('utf-8').split(' '):\n","                if word_vector_dict.has_key(word):\n","                    question_seq.append(word_vector_dict[word])\n","            for word in line_answer.decode('utf-8').split(' '):\n","                if word_vector_dict.has_key(word):\n","                    answer_seq.append(word_vector_dict[word])\n","        else:\n","            break\n","        question_seqs.append(question_seq)\n","        answer_seqs.append(answer_seq)\n","    file_object.close()\n","\n","def vector_sqrtlen(vector):\n","    len = 0\n","    for item in vector:\n","        len += item * item\n","    len = math.sqrt(len)\n","    return len\n","\n","def vector_cosine(v1, v2):\n","    if len(v1) != len(v2):\n","        sys.exit(1)\n","    sqrtlen1 = vector_sqrtlen(v1)\n","    sqrtlen2 = vector_sqrtlen(v2)\n","    value = 0\n","    for item1, item2 in zip(v1, v2):\n","        value += item1 * item2\n","    return value / (sqrtlen1*sqrtlen2)\n","\n","\n","def soft_acc(y_true, y_pred):\n","    return K.mean(K.equal(K.round(y_true*10), K.round(y_pred*10)))\n"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"id":"BSJcAudYcQWw","executionInfo":{"status":"ok","timestamp":1619411424578,"user_tz":240,"elapsed":172,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["import os\n","\n","pretrained_path = 'uncased_L-2_H-128_A-2'\n","config_path = os.path.join(pretrained_path, 'bert_config.json')\n","checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n","vocab_path = os.path.join(pretrained_path, 'vocab.txt')"],"execution_count":89,"outputs":[]},{"cell_type":"code","metadata":{"id":"inMesQoFcWRe","executionInfo":{"status":"ok","timestamp":1619411450955,"user_tz":240,"elapsed":174,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["os.environ['TF_KERAS'] = '1'"],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkC2VczxccMm","executionInfo":{"status":"ok","timestamp":1619411466387,"user_tz":240,"elapsed":263,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["import codecs\n","\n","token_dict = {}\n","with codecs.open(vocab_path, 'r', 'utf8') as reader:\n","    for line in reader:\n","        token = line.strip()\n","        token_dict[token] = len(token_dict)\n","token_dict_inv = {v: k for k, v in token_dict.items()}"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"id":"ucyEIK9ocg-O","executionInfo":{"status":"ok","timestamp":1619411672977,"user_tz":240,"elapsed":626,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["def vector2word(vector):\n","    max_cos = -10000\n","    match_word = ''\n","    for word in token_dict_inv:\n","        v = token_dict_inv[word]\n","        cosine = vector_cosine(vector, v)\n","        if cosine > max_cos:\n","            max_cos = cosine\n","            match_word = word\n","    return (match_word, max_cos)"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"id":"EyqKe-a4ZBhJ","executionInfo":{"status":"ok","timestamp":1619452425305,"user_tz":240,"elapsed":549,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["my_seq2seq = MySeq2Seq(word_vec_dim=word_vec_dim, max_seq_len=max_seq_len)"],"execution_count":194,"outputs":[]},{"cell_type":"code","metadata":{"id":"BYfjIq7jdXdH","executionInfo":{"status":"ok","timestamp":1619411697127,"user_tz":240,"elapsed":298,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["from keras import backend as K"],"execution_count":94,"outputs":[]},{"cell_type":"code","metadata":{"id":"NAiCzFOtdWcY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UpU7weWcvv3s"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P8bnfa7Dvv_K","executionInfo":{"status":"ok","timestamp":1619452600641,"user_tz":240,"elapsed":182,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["my_seq2seq2 = MySeq2Seq(word_vec_dim=word_vec_dim, max_seq_len=max_seq_len)"],"execution_count":204,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJ7Fvp4wv3yL","executionInfo":{"status":"ok","timestamp":1619452614276,"user_tz":240,"elapsed":12557,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"abe1cf98-0233-4de4-f959-c3bffcfafefe"},"source":["my_seq2seq2.load()"],"execution_count":205,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_22855\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_13 (InputLayer)           [(None, None, 128)]  0                                            \n","__________________________________________________________________________________________________\n","input_14 (InputLayer)           [(None, None, 128)]  0                                            \n","__________________________________________________________________________________________________\n","lstm_6 (LSTM)                   [(None, 128), (None, 131584      input_13[0][0]                   \n","__________________________________________________________________________________________________\n","lstm_7 (LSTM)                   [(None, None, 128),  131584      input_14[0][0]                   \n","                                                                 lstm_6[0][1]                     \n","                                                                 lstm_6[0][2]                     \n","__________________________________________________________________________________________________\n","sequential_3 (Sequential)       (None, None, 128)    66048       lstm_7[0][0]                     \n","==================================================================================================\n","Total params: 329,216\n","Trainable params: 329,216\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"djea1pWJwB37","executionInfo":{"status":"ok","timestamp":1619452614520,"user_tz":240,"elapsed":237,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["\n","testX1 ='Have fun tonight?'\n","testX2 =\"you have my word,  as a gentleman\"\n","testX3 ='do you listen to this crap'\n","testX4 ='i figured youd get to the good stuff eventually'\n","testX5 ='what good stuff'\n","testX6 ='wow'\n","testX7 ='she okay'\n","testX8 ='It\\'s more'\n","testX9 ='did you change your hair'\n","testX10 ='Let go!'\n","testX = [testX1,testX2,testX3,testX4,testX5,testX6,testX8,testX7,testX9,testX10]"],"execution_count":206,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z3BIVQ9DyyAI","executionInfo":{"status":"ok","timestamp":1619451655997,"user_tz":240,"elapsed":2505,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"99b3f313-a9d7-4ea9-d5dd-8d5028e56a1e"},"source":["str = 'Have fun tonight?'\n","import re\n","str =re.sub(r'[^A-Za-z0-9 -]+', '', str.lower())\n","question_seq = extract_embeddings(model_path, [str])\n","question_seq = question_seq\n","X = []\n","y = []\n","tmp1 = question_seq\n","[tmp1] = tmp1\n","tmp1 = tmp1.tolist()\n","tmp1 = [np.array(tmpp) for tmpp in tmp1]\n","if len(tmp1) < max_seq_len:\n","                #sequence_x =  list(tmp1) + [np.zeros(word_vec_dim)] * (self.max_seq_len - len(tmp1))\n","                sequence_x = list(tmp1) + [0* np.ones(word_vec_dim)] * (\n","                            max_seq_len - len(question_seq))"],"execution_count":164,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c9e2a1320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c9e2a1320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oeLjjD6h0Fx9","executionInfo":{"status":"ok","timestamp":1619451220756,"user_tz":240,"elapsed":169,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"3ff13e10-dc9f-4174-8f17-8b79ee21240b"},"source":["len(tmp1)"],"execution_count":155,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":155}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Vz0ngaF0JoF","executionInfo":{"status":"ok","timestamp":1619451231557,"user_tz":240,"elapsed":212,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"771306e3-5d81-49d3-f6ae-0633eb19c708"},"source":["len(tmp1[0])"],"execution_count":156,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128"]},"metadata":{"tags":[]},"execution_count":156}]},{"cell_type":"code","metadata":{"id":"ptUyQl8Y0MR6","executionInfo":{"status":"ok","timestamp":1619451249665,"user_tz":240,"elapsed":161,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["kz = [0* np.ones(word_vec_dim)] * (\n","                            max_seq_len - len(question_seq))"],"execution_count":157,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uW3kh57s0Qtl","executionInfo":{"status":"ok","timestamp":1619451290438,"user_tz":240,"elapsed":386,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"cd2937de-3bc7-4fa1-ec7e-6391404de6a5"},"source":["np.shape(kz)"],"execution_count":160,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9, 128)"]},"metadata":{"tags":[]},"execution_count":160}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zVGjNzjgz3zc","executionInfo":{"status":"ok","timestamp":1619451659977,"user_tz":240,"elapsed":386,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"2f458d55-cd2a-4ea2-a405-cdba7189dd8a"},"source":["sequence_x"],"execution_count":165,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([-1.29485559e+00, -2.14129090e-01, -2.85094738e+00, -1.98327637e+00,\n","         3.89618695e-01,  1.15067780e+00,  1.46932125e-01,  2.49609613e+00,\n","        -1.96652126e+00,  2.63208635e-02,  7.09880233e-01,  3.83294761e-01,\n","        -1.33765066e+00,  5.82899213e-01,  2.14976740e+00, -1.32491839e+00,\n","         1.04852080e+00, -6.81312740e-01, -1.67227352e+00,  8.06618094e-01,\n","        -1.06836390e+00, -5.75590491e-01,  2.68891263e+00,  5.33423185e-01,\n","         7.89784729e-01, -9.70524430e-01,  1.10562837e+00,  7.55183876e-01,\n","         1.18872985e-01, -1.43736649e+00, -1.06693912e+00, -1.26755941e+00,\n","        -1.69631362e+00,  1.28626812e+00,  5.24123728e-01, -7.57753313e-01,\n","        -7.60401189e-01, -6.29025400e-01, -1.76945245e+00, -1.77697229e+00,\n","         1.77378666e+00, -1.83434081e+00,  9.23717558e-01, -7.45762646e-01,\n","        -4.65715528e-02, -1.65405869e+00, -5.93829632e-01, -5.01224518e-01,\n","         2.91868865e-01, -3.67331594e-01,  5.28004885e-01,  1.97760594e+00,\n","         5.88671207e-01, -2.07837790e-01,  1.15225828e+00, -1.36840391e+00,\n","         4.08831775e-01, -3.21511298e-01, -3.85902941e-01,  1.65026748e+00,\n","         1.01488006e+00, -1.13151145e+00, -1.37156582e+00, -1.01041865e+00,\n","        -1.48257959e+00,  4.57489192e-01,  2.62732565e-01,  1.32457161e+00,\n","        -5.49345374e-01, -2.56263852e-01, -4.37008888e-01, -1.22916237e-01,\n","        -8.76282305e-02, -1.88706815e-03, -2.73592621e-01, -9.77420151e-01,\n","         7.07543939e-02,  4.27774712e-02,  2.51772070e+00,  5.77059388e-01,\n","         8.13539803e-01,  1.01705658e+00,  1.39694309e+00,  1.53135490e+00,\n","        -5.53947806e-01, -3.35693806e-01,  5.45501590e-01, -6.92973256e-01,\n","         2.65847921e+00, -1.17526650e+00,  1.65898871e+00, -2.00116441e-01,\n","        -1.26620185e+00,  1.01925039e+00,  4.02859032e-01, -1.09908372e-01,\n","        -3.09552491e-01,  6.06724977e-01,  6.92986131e-01,  3.93345028e-01,\n","        -8.48903120e-01, -4.50989991e-01,  5.22784472e-01, -9.01592731e-01,\n","         6.03947759e-01, -1.02509356e+00,  3.44861448e-01,  5.13324142e-01,\n","         5.76827705e-01, -1.07544935e+00,  3.15629810e-01,  3.02289069e-01,\n","         6.42385125e-01,  4.13161784e-01, -2.41268992e-01,  6.96979523e-01,\n","        -2.23951694e-02, -1.62921000e+00,  7.19340980e-01, -1.23444688e+00,\n","        -7.94075608e-01,  1.61208296e+00,  7.72161633e-02, -1.85654140e+00,\n","        -1.73363924e+00, -4.31202859e-01, -4.11758453e-01, -1.21484376e-01]),\n"," array([-0.62878746,  0.2839466 , -0.03378284, -0.64950192,  0.21791916,\n","        -0.34854504,  0.47818139,  1.71387613, -0.68290132, -0.97358435,\n","         0.6873256 ,  0.56639349, -0.73009276, -0.22523952,  1.9137516 ,\n","        -1.29521155,  0.72228998,  0.5270108 , -1.59411836,  1.14777827,\n","        -1.338835  , -0.88361979,  1.9682287 ,  0.77068824,  1.34338915,\n","        -1.04732037,  1.20787156,  0.71927071,  0.50234455, -1.41790581,\n","        -1.60543776, -1.22104478, -0.67371422,  0.83221394,  0.88660258,\n","        -1.30683863, -0.55668795, -1.98359048, -1.82858658, -1.58380723,\n","         1.3901875 ,  0.02644043, -1.11342037, -0.45178866, -0.66972685,\n","        -1.32333076, -0.6360985 ,  0.70932794, -0.15471165,  1.16575706,\n","         2.55110335,  1.94683635,  1.22026205,  0.24874859,  1.25376785,\n","         0.75274491,  0.62035918, -0.66694701, -0.13210355,  1.75197446,\n","         0.16194433, -0.11473447, -2.02350545,  0.39938185, -2.24862003,\n","        -0.11383294, -0.39833605,  2.7265718 , -0.27826375,  0.68175352,\n","        -1.93954098,  0.18941893, -0.12996526, -0.67231566, -0.59883761,\n","        -0.95637208, -0.5482983 , -0.44750118,  2.23212624, -0.11637785,\n","         0.87748116, -0.81961906,  1.34221649,  1.38208008, -0.29507524,\n","         0.30979776,  0.67758214,  0.07401414,  0.76781845, -0.76075161,\n","         0.71078086, -0.05096184, -2.81536531,  0.50217593,  0.6743359 ,\n","        -1.41754627,  0.02757457,  0.03912485,  0.59837317,  0.28369975,\n","        -0.86741924, -0.62907171,  0.14626692, -1.22526026,  0.99244416,\n","        -0.91832268,  0.26261574,  0.29794681,  0.45201886, -0.51285547,\n","        -0.16166276,  0.23666592,  2.09512496,  0.69126368, -0.21817614,\n","         0.53681916,  0.76685947, -1.2100178 , -0.39330029, -1.74203765,\n","         0.09225331,  1.54201376, -0.25164446, -1.93981957, -1.92232347,\n","        -1.55094135, -1.62398672,  0.55572325]),\n"," array([-1.10770667, -1.32057619, -0.70745134, -0.53145289,  1.83990645,\n","        -0.50764197,  0.08831596,  0.9555645 , -1.32551241, -1.14264965,\n","         1.3777169 ,  0.73729116, -0.84542656,  0.76119643,  1.06482196,\n","        -0.94713628,  0.55049866, -0.30882877, -0.57045513,  1.53690171,\n","        -0.79701036,  0.56847948,  0.7518391 ,  0.28763843,  1.26296639,\n","        -0.86825454,  1.71208155,  1.64902604,  0.30106205,  0.06703368,\n","        -2.07156992, -0.49435338, -0.15019539,  1.17502666,  1.33902836,\n","        -0.22228011, -0.28723094, -0.92940563, -1.58506465, -1.77685833,\n","         0.82414448, -0.81950754, -1.2165283 , -0.13481393,  1.06858397,\n","        -1.21138191, -0.01859978, -0.47141346,  0.7813049 ,  0.21143857,\n","         0.56963789,  1.53894198,  0.9379307 , -0.40055582,  0.40691251,\n","        -1.47023857,  1.22792792, -1.42757821,  0.09066422,  0.02125478,\n","         0.3196491 , -1.66688919, -1.35270357, -1.63933277, -1.65275514,\n","         1.46011734,  0.34189749,  0.9241963 , -0.74166691, -0.46018544,\n","        -0.31691903,  0.30152017,  0.96623713, -0.81825894, -0.8279866 ,\n","         0.30806711,  0.62829024, -0.31656677,  3.40722871, -1.1534245 ,\n","        -0.30409259, -1.01979792,  0.65017664,  0.93813467,  0.44176292,\n","        -0.22479078,  0.22462393, -0.191122  ,  1.30168962, -1.01340032,\n","         1.87862897, -0.50614369, -1.97773468,  1.62419319, -0.40233713,\n","        -1.12435746,  0.38054699,  1.84340107,  0.57774234, -0.02956066,\n","        -0.7256394 , -0.98880297,  0.03694251, -0.95968699,  0.911026  ,\n","        -1.62270582, -0.56049156, -1.17335796,  1.92786491, -0.1211305 ,\n","         0.83746099,  0.2643699 ,  1.4029026 , -0.42754233, -0.12791829,\n","         0.32403961, -0.24495062, -1.01055217, -0.95316625, -0.1389727 ,\n","         0.00981788,  1.84453678,  1.13530552, -3.04360747, -0.96123391,\n","        -1.81950629, -0.85299206, -0.09431051]),\n"," array([-1.92632329, -0.29193142, -0.62783384, -1.1459142 ,  0.81364191,\n","         0.71343005,  0.07752889,  0.95980471, -1.29669142, -0.50909412,\n","         1.24555135,  1.00196195, -0.81028104,  0.79684967,  1.86935079,\n","        -1.66973841,  0.21137705, -0.47212803, -1.09440041,  1.01017809,\n","        -1.11930609,  0.39917684,  1.11382866,  0.04369468,  0.87980026,\n","        -1.16839969,  0.60528755,  0.38832554,  0.12896363, -1.05949938,\n","        -0.62954944, -0.92905444, -0.23622651,  1.38816571,  0.16099069,\n","         0.30302823,  0.27271539, -0.30668527, -2.84807181, -1.07261062,\n","         0.92269838, -0.50763583,  0.48381317, -1.19973123, -0.44660285,\n","        -1.31638002, -0.4155508 ,  0.08085471,  0.4756    ,  0.21235427,\n","         1.12648356,  2.08499742,  0.75267112, -0.91419268,  0.10277484,\n","        -2.1708734 ,  0.9401201 , -0.14009477, -0.57002169,  0.8507486 ,\n","         1.36027503, -0.9927417 , -1.18052375, -1.41643071, -0.8939296 ,\n","         0.68282861,  0.25012252,  0.99953324, -1.32844293, -0.60708642,\n","        -1.10139465, -0.02344541, -0.07015739, -0.58667964, -1.09697461,\n","        -1.16575909,  0.34568471, -1.0905683 ,  3.07858849,  0.23438707,\n","        -0.03788089,  1.22948802,  1.4336406 ,  0.67619938,  0.6509527 ,\n","         0.17596538,  0.51734155, -0.72924507,  2.54913974, -0.8877722 ,\n","         2.03089094, -0.04233508, -1.32583582,  1.42908108, -0.03926633,\n","         0.11520649,  0.14369819,  1.21529424,  0.63742721,  1.19403243,\n","        -0.89431238, -1.16812098,  0.68210864, -1.3681097 ,  0.89550388,\n","        -2.10433865,  0.10389373, -0.52782148,  1.36168158, -0.47717783,\n","         1.11969483,  0.57206452,  1.46639538, -0.46550354, -0.78218204,\n","         0.11776584,  0.01723894, -1.91312325,  0.14365323, -0.78819507,\n","        -0.32610619,  1.89933288,  0.30540758, -3.0863061 , -1.22748232,\n","        -2.75908375,  0.59422147,  0.20254433]),\n"," array([-2.32648492,  0.49305955,  0.12736154, -1.79521024,  0.29077026,\n","         2.01036239,  0.44097021,  0.60860175, -1.91927409,  0.00711948,\n","         0.83789712,  0.16249606, -1.4325949 ,  0.21097565,  2.17978764,\n","        -2.5348537 ,  0.1803641 ,  0.13041507, -0.79991686,  0.80075151,\n","        -0.61044025, -0.36305159,  1.62305355,  0.42043412,  0.86941481,\n","        -0.99882281,  0.63661951,  0.62157989,  0.22692527, -1.36009395,\n","        -0.89073789, -1.28972185, -0.28958008,  1.314484  , -0.16316621,\n","         0.03344062,  0.08557935, -0.62561172, -1.53915095, -0.93265599,\n","         1.31907654, -0.56944394,  1.75951076, -1.25230086, -0.35042197,\n","        -0.32286879, -1.37349439, -1.01806402,  0.45388404, -0.76614016,\n","         0.41041535,  1.66724122,  0.22542912, -0.77870274,  0.17633756,\n","        -0.80856085,  0.96903032,  0.0704456 , -0.30983087,  1.51069188,\n","         0.89911437, -0.61281407, -1.74938548, -0.5428856 , -1.39107883,\n","         0.52223253,  0.42444813,  1.12291229, -1.13401723, -0.18632522,\n","        -1.14979935, -0.39210036, -0.35615063, -0.82075423, -0.79275805,\n","        -0.74388635,  0.26104611, -1.36291492,  1.32814598,  0.7658022 ,\n","         0.34825522, -0.57112652,  1.05947959,  0.67446685,  0.02107754,\n","        -0.69470608, -0.65083998, -0.87151808,  2.30322361, -1.20248544,\n","         2.89862299,  0.2572386 , -1.68271923,  1.42766845,  0.75815177,\n","         0.78253716,  0.35617322,  0.32305464,  0.8271296 ,  0.52212918,\n","        -2.20700359, -0.32975745,  0.80667335, -1.11802232,  1.08050597,\n","        -1.90375578,  0.61011744,  0.49599725,  0.61526388, -0.55204827,\n","         0.15091145,  1.14229357,  2.05242848,  0.86181736,  0.14879036,\n","         1.28192568,  0.34693015, -1.93974948, -0.37047547, -0.50988108,\n","         0.14118077,  1.3931073 , -0.02950007, -2.56476164, -1.05940008,\n","        -1.45849872, -0.40473175,  1.00455999]),\n"," array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n"," array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n"," array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n"," array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n"," array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n"," array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n"," array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n"," array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n"," array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0.])]"]},"metadata":{"tags":[]},"execution_count":165}]},{"cell_type":"code","metadata":{"id":"ZCjrVk286OcF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L2SmMcvrwqy2","executionInfo":{"status":"ok","timestamp":1619452627048,"user_tz":240,"elapsed":5268,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"96dbc741-9695-4b81-b335-a6ffd94f7695"},"source":[" testXX = my_seq2seq2.generate_test(testX1)"],"execution_count":207,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c976b1560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c976b1560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hyqMyGFCyhPJ","executionInfo":{"status":"ok","timestamp":1619452495861,"user_tz":240,"elapsed":417,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["nb =[na.tolist() for na in testXX[0]]"],"execution_count":200,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ih4Uwvdr3gk2","executionInfo":{"status":"ok","timestamp":1619452497988,"user_tz":240,"elapsed":680,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"23022fce-f8c8-4476-e936-cdcb82aa284b"},"source":["nb = np.array(nb)"],"execution_count":201,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DkD8bJR4T_n","executionInfo":{"status":"ok","timestamp":1619453114065,"user_tz":240,"elapsed":329,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"2cf7b66f-7c50-458e-de48-69381b34e306"},"source":["len(nb[5])"],"execution_count":220,"outputs":[{"output_type":"execute_result","data":{"text/plain":["200"]},"metadata":{"tags":[]},"execution_count":220}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":197},"id":"_pUIDMYOxf_U","executionInfo":{"status":"error","timestamp":1619452673386,"user_tz":240,"elapsed":966,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"236305a4-de80-4c74-d586-29584645e01a"},"source":["predict = my_seq2seq2.mypredict(testXX, max_seq_len, word_vec_dim)\n","print(\"\\n\")\n","print(testX1)\n","\n","for w in predict:\n","        # print(w)\n","        (match_word, max_cos, eosdist) = vector2word(w)\n","        if(match_word[0][1] <  0.6):\n","           break\n","        print(match_word, vector_sqrtlen(w), \"  \", eosdist)"],"execution_count":211,"outputs":[{"output_type":"stream","text":["\n","\n","Have fun tonight?\n"],"name":"stdout"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rfcTYtSY6UAj","executionInfo":{"status":"ok","timestamp":1619452853200,"user_tz":240,"elapsed":173,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["predict0 = predict[0]"],"execution_count":212,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5mWokBil6Ycz","executionInfo":{"status":"ok","timestamp":1619452860715,"user_tz":240,"elapsed":586,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"3e28eac8-dd52-4216-efb1-c61bb3d99732"},"source":["predict0"],"execution_count":213,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.69180506,  0.4026589 , -1.939438  , -1.1189653 , -0.21768863,\n","        0.5073965 ,  0.07968546,  0.57965124, -0.43340355,  0.7392013 ,\n","        0.67940027, -0.3604221 , -1.4776    ,  0.3892886 ,  1.7091602 ,\n","       -0.7188203 , -0.31905043,  0.05204627, -1.4533765 ,  0.7278389 ,\n","       -0.17760351, -0.08913042,  1.653678  ,  0.14793953,  0.47093737,\n","       -0.39816988,  0.4972838 ,  0.6214813 ,  0.25860184, -0.01979379,\n","       -0.52762425, -1.3060529 , -0.77410907,  0.5636999 ,  0.42371267,\n","       -1.216814  ,  0.13049692, -0.26267973, -1.1138179 , -1.1489426 ,\n","        1.1169072 , -0.892715  ,  0.75676763, -0.8865153 , -0.23759688,\n","       -1.5581158 , -0.21461837, -0.6857289 ,  0.36782655,  0.13229069,\n","        0.04508353,  0.7291424 ,  0.3099703 , -0.05992098,  0.7172866 ,\n","       -0.6836921 ,  0.24160744, -0.06818961, -0.5716443 ,  0.9411679 ,\n","        1.2535756 , -1.0820894 , -0.7825355 , -0.344931  , -0.4709722 ,\n","        0.4364276 , -0.0944005 ,  0.32162768,  0.8698002 ,  0.4800306 ,\n","       -0.45513576,  0.2146058 , -0.00308801, -0.33567262, -0.14434335,\n","        0.17982557,  0.26254502,  0.41109586,  1.0744125 ,  0.19016346,\n","        0.23749524,  0.29997724,  0.5425479 ,  0.33390367, -0.27897245,\n","        0.36280823,  0.01494472, -0.16289423,  1.4403083 , -0.45860478,\n","        0.8392882 ,  0.07532908, -0.73918295,  0.86667544,  0.64270097,\n","        0.54664624,  0.1175603 ,  0.130932  , -0.16274717,  0.36591858,\n","       -0.5534716 , -0.42126572,  0.53381073, -0.7201516 ,  0.28919563,\n","       -1.2664406 , -0.43079963,  0.14454107,  0.31681803, -1.0014243 ,\n","        0.46499228,  0.51243037, -0.17785928, -0.32093182, -0.08785963,\n","        0.48797902, -0.57743627, -0.76027346,  0.7525074 , -0.37176526,\n","       -0.28296882,  0.6777817 ,  0.6735986 , -0.19798368, -1.0013243 ,\n","       -0.41668934, -0.3415009 , -0.35257992], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":213}]},{"cell_type":"code","metadata":{"id":"_5KdxQfH6aPv","executionInfo":{"status":"ok","timestamp":1619452919446,"user_tz":240,"elapsed":185,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}}},"source":["max_cos = -10000\n","match_word = ''\n","vector = predict0"],"execution_count":216,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163},"id":"kr14P_vv6dzb","executionInfo":{"status":"error","timestamp":1619453014434,"user_tz":240,"elapsed":468,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"d23103bf-1e26-4e0f-a93e-fc9fef4e7b3d"},"source":["for word in token_dict_inv:\n","        v = token_dict_inv[word]\n","        cosine = vector_cosine(vector, v)\n","        if cosine > max_cos:\n","            max_cos = cosine\n","            match_word = word\n"],"execution_count":219,"outputs":[{"output_type":"stream","text":["/bin/bash: line 0: fg: no job control\n"],"name":"stdout"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"4YO4Fo03Sral","executionInfo":{"status":"error","timestamp":1619459457604,"user_tz":240,"elapsed":175,"user":{"displayName":"Yune Lilias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPL9uZ2LdSCWGJOgoSPF4_9xn_BFMy40VTSKMg=s64","userId":"18207685848019699455"}},"outputId":"90147d99-3a81-4384-fc7e-c8aae1f2a599"},"source":[""],"execution_count":227,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-227-2797f1554fb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m17882\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13406\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mp11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'padding percentage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"]}]}]}